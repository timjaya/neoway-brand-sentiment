{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Benepar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "[nltk_data] Downloading package benepar_en2 to\n",
      "[nltk_data]     C:\\Users\\jyzho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package benepar_en2 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import benepar\n",
    "benepar.download(\"benepar_en2\")\n",
    "parser = benepar.Parser(\"benepar_en2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(reviews, brandlist, sample_size=2000, validation_size=0.1, \n",
    "               test_size=0.25, verbose=0, **kwargs):\n",
    "    \"\"\"Function that generates the dataset for Spacy training. \n",
    "    \n",
    "    Input: Yelp dataset\n",
    "    Output: train/test CSV for ER model training\n",
    "    Parameters:\n",
    "    - reviews: pandas dataframe of reviews\n",
    "    - brandlist: pandas dataframe containing list of products/brands\n",
    "    - sample_size: total number of reviews to subset\n",
    "    - validation_size: proportion of total sample_size to validate on\n",
    "    - test_size: proportion of total sample_size that will serve as the test set\n",
    "    \n",
    "    NOTE \n",
    "    ----\n",
    "    config.data_path: workspace/data\n",
    "    You should use workspace/data to put data to working on.  Let's say\n",
    "    you have workspace/data/iris.csv, which you downloaded from:\n",
    "    https://archive.ics.uci.edu/ml/datasets/iris. You will generate\n",
    "    the following:\n",
    "    + workspace/data/test.csv\n",
    "    + workspace/data/train.csv\n",
    "    + workspace/data/validation.csv\n",
    "    + other files\n",
    "    With these files you can train your model!\n",
    "    \"\"\"\n",
    "    if verbose == 1:\n",
    "      print(\"==> GENERATING DATASETS FOR TRAINING YOUR MODEL\")\n",
    "\n",
    "    # Convert brands in brand list to lowercase\n",
    "    brandlist.word = brandlist.word.str.lower()\n",
    "\n",
    "    # Extract a sample of reviews to generate training/validation/test data from\n",
    "    sample = reviews.sample(n=sample_size)\n",
    "\n",
    "    # Convert reviews to format relevant for spacy training\n",
    "    if verbose == 1:\n",
    "      print(\"   ===> CONVERTING DATA FOR SPACY\")\n",
    "    train_data = []\n",
    "    print(\"LENGTH OF DATASET: \", len(sample))\n",
    "    for index, row in tqdm(sample.iterrows()):\n",
    "        # print(index)\n",
    "        brands_tmp = []\n",
    "        for brand in brandlist.word:\n",
    "            text = row.text.lower()\n",
    "            start_index = 0\n",
    "            while start_index < len(text):\n",
    "                start_index = text.find(brand, start_index)\n",
    "                end_index = start_index + len(brand)\n",
    "                if start_index == -1:\n",
    "                    break\n",
    "                if not text[start_index-1].isalpha() and (end_index == len(text) or not text[end_index].isalpha()):\n",
    "                    if brand not in ['place', 'restaurant', 'cafe', 'establishment', 'diner']:\n",
    "                        brands_tmp.append((start_index, end_index, \"PRODUCT\"))\n",
    "                    else:\n",
    "                        brands_tmp.append((start_index, end_index, \"PRODUCT\"))\n",
    "\n",
    "                start_index += len(brand)\n",
    "        train_data.append((row.review_id, row.text, brands_tmp))\n",
    "\n",
    "    result = pd.DataFrame(train_data, columns=['review_id', 'text', 'entities'])\n",
    "\n",
    "    # Split processed data into train/validation/test sets\n",
    "    if verbose == 1:\n",
    "      print(\"   ===> SPLITTING INTO TRAIN/VALIDATION/TEST SETS\")\n",
    "    train_validation, test = train_test_split(result, test_size=test_size)\n",
    "    train, validation = train_test_split(train_validation, test_size=validation_size / (1-test_size))\n",
    "\n",
    "    # Output to CSV in data folder\n",
    "    train.to_csv('../workspace/data/train.csv')\n",
    "    validation.to_csv('../workspace/data/validation.csv')\n",
    "    test.to_csv('../workspace/data/test.csv')\n",
    "    \n",
    "    if verbose == 1:\n",
    "      print(\"==> DATASETS GENERATED\")\n",
    "    \n",
    "    return train, validation, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training entity recognition model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "import ast \n",
    "import plac\n",
    "import random\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def create_train_data(df):\n",
    "    train_data = []\n",
    "    newnlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        doc = newnlp(df['text'].iloc[i])\n",
    "        entity_list = df['entities_clean'].iloc[i]\n",
    "        for ent in doc.ents:\n",
    "            entity_list.append((ent.start_char, ent.end_char, ent.label_))\n",
    "        entity_dict = {\"entities\": entity_list}\n",
    "        train_data.append((df['text'].iloc[i], entity_dict))\n",
    "    return train_data\n",
    "\n",
    "def create_test_data(df):\n",
    "    test_data = []\n",
    "    newnlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        doc = newnlp(df['text'].iloc[i])\n",
    "        entity_list = df['entities_clean'].iloc[i]\n",
    "        for ent in doc.ents:\n",
    "            entity_list.append((ent.start_char, ent.end_char, ent.label_))\n",
    "        entity_dict = {\"entities\": entity_list}\n",
    "        test_data.append((df['text'].iloc[i], entity_dict))\n",
    "    return test_data\n",
    "\n",
    "\n",
    "# new entity label\n",
    "def train(train_data, test_data, LABEL, model='en_core_web_sm', new_model_name=\"product\", output_dir='../ermodel', n_iter=1):\n",
    "    \"\"\"Set up the pipeline and entity recognizer, and train the new entity.\"\"\"\n",
    "    random.seed(0)\n",
    "    if model is not None:\n",
    "        nlp = spacy.load(model)  # load existing spaCy model\n",
    "        print(\"Loaded model '%s'\" % model)\n",
    "    else:\n",
    "        nlp = spacy.blank(\"en\")  # create blank Language class\n",
    "        print(\"Created blank 'en' model\")\n",
    "    # Add entity recognizer to model if it's not in the pipeline\n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe(\"ner\")\n",
    "        nlp.add_pipe(ner)\n",
    "    # otherwise, get it, so we can add labels to it\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "    ner.add_label(LABEL)  # add new entity label to entity recognizer\n",
    "    if model is None:\n",
    "        optimizer = nlp.begin_training()\n",
    "    else:\n",
    "        optimizer = nlp.resume_training()\n",
    "    move_names = list(ner.move_names)\n",
    "    # get names of other pipes to disable them during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        sizes = compounding(1.0, 4.0, 1.001)\n",
    "        # batch the examples using spaCy's minibatch\n",
    "        start = time.time()\n",
    "        for itn in range(n_iter):\n",
    "            random.shuffle(train_data)\n",
    "            batches = minibatch(train_data, size=sizes)\n",
    "            losses = {}\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                nlp.update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)            \n",
    "            #print(\"Training Recall:\",nlp.evaluate(random.sample(TRAIN_DATA,200)).ents_r)\n",
    "            #print(\"Test Recall:\",nlp.evaluate(TEST_DATA).ents_p) #COMMENT: isn't this precision?\n",
    "            #COMMENT: so test data here is evaluating test_data which has the format \n",
    "            # of e.g. (\"Uber blew through $1 million a week\", {\"entities\": [(0, 4, \"ORG\")]}) right\n",
    "            #print(\"Training Losses\", losses)\n",
    "        end = time.time()\n",
    "    print(\"Total training time:\",end-start)\n",
    "\n",
    "    # test the trained model (small sample test)\n",
    "    for i in range(10):\n",
    "        test_text = test_data[i][0]\n",
    "        doc = nlp(test_text)\n",
    "        print(\"Entities in '%s'\" % test_text)\n",
    "        for ent in doc.ents:\n",
    "            print(ent.label_, ent.text)\n",
    "\n",
    "    # TODO: Abstract to another function\n",
    "    # save model to output directory\n",
    "    if output_dir is not None:\n",
    "        output_dir = Path(output_dir)\n",
    "        if not output_dir.exists():\n",
    "            output_dir.mkdir()\n",
    "        nlp.meta[\"name\"] = new_model_name  # rename model\n",
    "        nlp.to_disk(output_dir)\n",
    "        print(\"Saved model to\", output_dir)\n",
    "\n",
    "        # COMMENT: Abstract to another function \n",
    "        # test the saved model\n",
    "        print(\"Loading from\", output_dir)\n",
    "        nlp2 = spacy.load(output_dir)\n",
    "        # Check the classes have loaded back consistently\n",
    "        assert nlp2.get_pipe(\"ner\").move_names == move_names\n",
    "        doc2 = nlp2(test_text)\n",
    "        for ent in doc2.ents:\n",
    "            print(ent.label_, ent.text)\n",
    "    return nlp\n",
    "\n",
    "\n",
    "def run_training(file_name = \"../workspace/data/train.csv\", \n",
    "                 output_dir = '../workspace/models/er_model'):\n",
    "\n",
    "    print(\"   ==> CONFIGURING FORMAT FOR SPACY TRAINING\")\n",
    "\n",
    "    df = pd.read_csv(file_name)\n",
    "    df['entities_clean']=[ast.literal_eval(i) for i in df['entities']]\n",
    "    #train_df, test_df = train_test_split(df, test_size = .2)\n",
    "    all_train, _ = train_test_split(df, train_size=250)\n",
    "    train_df, test_df = train_test_split(all_train, test_size=.2)\n",
    "    \n",
    "    # new entity label\n",
    "    LABEL = \"PRODUCT\"\n",
    "    \n",
    "    TRAIN_DATA = create_train_data(train_df)\n",
    "    TEST_DATA = create_test_data(test_df)\n",
    "\n",
    "    print(\"   ==> TRAINING...\")\n",
    "\n",
    "    model = train(TRAIN_DATA, TEST_DATA, LABEL=LABEL, output_dir=output_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_train(**kwargs):\n",
    "    \"\"\"Function that will run your model, be it a NN, Composite indicator\n",
    "    or a Decision tree, you name it.\n",
    "\n",
    "    NOTE\n",
    "    ----\n",
    "    config.models_path: workspace/models\n",
    "    config.data_path: workspace/data\n",
    "\n",
    "    As convention you should use workspace/data to read your dataset,\n",
    "    which was build from generate() step. You should save your model\n",
    "    binary into workspace/models directory.\n",
    "    \"\"\"\n",
    "    print(\"==> TRAINING YOUR SPACY MODEL!\")\n",
    "\n",
    "    # TODO: Load data from workspace/data\n",
    "    # TODO: Save trained model to workspace/models\n",
    "    run_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Entity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(nlp_model, text):\n",
    "    \"\"\"\n",
    "    Input nlp_model and text, retrieve a list of unique entities from the text.\n",
    "    \"\"\"\n",
    "    doc = nlp_model(text)\n",
    "    entities = set()\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PRODUCT\":\n",
    "            entities.add(ent.text)\n",
    "    return list(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Helper Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import benepar\n",
    "import re\n",
    "import spacy\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "class Predictor:\n",
    "    def __init__(self,\n",
    "                 sentiment_package = \"vader\",\n",
    "                 parse_package = \"benepar\",\n",
    "                 model_dir = \"../workspace/models/er_model\"):\n",
    "        \n",
    "        self.sentiment_package = sentiment_package\n",
    "        self.nlp = spacy.load(model_dir)\n",
    "        self.num_cores = multiprocessing.cpu_count()\n",
    "        \n",
    "        if parse_package == 'benepar':\n",
    "            try:\n",
    "                self.parser = benepar.Parser(\"benepar_en2\") \n",
    "            except LookupError:\n",
    "                benepar.download('benepar_en2')\n",
    "                self.parser = benepar.Parser(\"benepar_en2\")\n",
    "        elif parse_package == 'stanford':   \n",
    "            pass\n",
    "        else:\n",
    "            raise Exception('incorrect parse package')\n",
    "        \n",
    "    def _remove_nestings(self, lst): \n",
    "        output = []\n",
    "        \n",
    "        def _remove_nestings_recursive(l):\n",
    "            for i in l: \n",
    "                if type(i) == list: \n",
    "                    _remove_nestings_recursive(i) \n",
    "                else: \n",
    "                    output.append(i)\n",
    "        \n",
    "        _remove_nestings_recursive(lst)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def _continue_splitting(self, review, list_of_dividers):    \n",
    "        temp = list_of_dividers.copy()\n",
    "        l = [review]\n",
    "        while len(temp) > 0:\n",
    "            divider = temp.pop(0)\n",
    "            l_new = []\n",
    "            for i in l:\n",
    "                l_new += i.split(divider)\n",
    "            l = l_new\n",
    "        return l\n",
    "    \n",
    "    \n",
    "    def join_clause(self, review, list_of_split_clauses, list_of_dividers):\n",
    "        output = []\n",
    "        loc_of_split_clauses = []\n",
    "        for clause in list_of_split_clauses:\n",
    "            loc_of_split_clauses.append(review.find(clause))\n",
    "        for divider in list_of_dividers:\n",
    "            print(divider)\n",
    "            loc_div = review.find(divider)\n",
    "            print(loc_div)\n",
    "            for i in range(len(loc_of_split_clauses)):\n",
    "                if loc_div > loc_of_split_clauses[i]:\n",
    "                    print(loc_div,loc_of_split_clauses[i])\n",
    "    \n",
    "    \n",
    "    def join_partitions(self, long_review,entity_with_review):\n",
    "        loclist = []\n",
    "        for (_, clause) in entity_with_review:\n",
    "            loclist.append((long_review.find(clause),long_review.find(clause)+len(clause)))\n",
    "        starts = {i for (i,j) in loclist}\n",
    "        ends = {j for (i,j) in loclist}\n",
    "        starts.add(len(long_review))\n",
    "        newends = {}\n",
    "        for i in ends:\n",
    "            newends[i] = min([x for x in starts if x >= i])\n",
    "        for i in newends:\n",
    "            pass\n",
    "        new_entity_with_review = []\n",
    "        for i in range(len(loclist)):\n",
    "            tup = loclist[i]\n",
    "            entity = entity_with_review[i][0]\n",
    "            st = tup[0]\n",
    "            en = newends[tup[1]]\n",
    "            new_entity_with_review.append((entity,long_review[st:en]))\n",
    "        return new_entity_with_review\n",
    "    \n",
    "    \n",
    "    def split_long_string(self, review):\n",
    "        num = len(review)\n",
    "        split_list = []\n",
    "        start = 0\n",
    "        end = 0\n",
    "        while num != end:\n",
    "            #if one step away from end of review\n",
    "            if num - end < 1000:\n",
    "                end = num\n",
    "                split_list.append(review[start:end])\n",
    "            \n",
    "            #otherwise, find the last full stop\n",
    "            else:\n",
    "                end = review[start:(start+1000)].rfind('.') + start\n",
    "                if end == -1:\n",
    "                    end = review[start:(start+1000)].rfind(' ') + start #if no '.', space will do\n",
    "                    if end == -1:\n",
    "                        end = min(start + 1000,num) + start #if there still isn't, then we simply split\n",
    "                split_list.append(review[start:end])\n",
    "                start = end\n",
    "        return(split_list)\n",
    "    \n",
    "    \n",
    "    def split_very_long_string(self, review):\n",
    "        num = len(review)\n",
    "        split_list = []\n",
    "        start = 0\n",
    "        end = 0\n",
    "        while num != end:\n",
    "            #if one step away from end of review\n",
    "            if num - end < 1000:\n",
    "                end = num\n",
    "                split_list.append(review[start:end])\n",
    "            \n",
    "            #otherwise, find the last full stop\n",
    "            else:\n",
    "                end = review[start:(start+400)].rfind('.') + start\n",
    "                if end == -1:\n",
    "                    end = review[start:(start+400)].rfind(' ') + start #if no '.', space will do\n",
    "                    if end == -1:\n",
    "                        end = min(start + 400,num) + start #if there still isn't, then we simply split\n",
    "                split_list.append(review[start:end])\n",
    "                start = end\n",
    "        return(split_list)\n",
    "    \n",
    "    \n",
    "    def split_review_naive(self, review,entities):\n",
    "        clauses = re.split('[.?!]',review)\n",
    "        lenlist = [len(x) for x in clauses]\n",
    "        clauses = [x for _, x in sorted(zip(lenlist,clauses),reverse=False)]\n",
    "        entity_with_clause = []\n",
    "        for entity in entities:\n",
    "            for clause in clauses:\n",
    "                if entity in clause:\n",
    "                    entity_with_clause.append((entity,clause))\n",
    "                    break\n",
    "        return(self.join_partitions(review,entity_with_clause))\n",
    "    \n",
    "    \n",
    "    def min_tree(self, review, entities, output = 'minimum'):\n",
    "        \n",
    "        #review is string, entities is list of strings, parser is parser object\n",
    "        #possible outputs: no_parse, minimum, partition, all\n",
    "        \n",
    "        if output == 'no_parse':\n",
    "            return(self.split_review_naive(review,entities))\n",
    "            \n",
    "        treelist = []\n",
    "        lenlist = []\n",
    "        temp = review.split('\\n')\n",
    "        \n",
    "        if len(review) > 1000:\n",
    "            split_reviews = self.split_long_string(review)\n",
    "        else:\n",
    "            split_reviews = [i for i in temp if len(i) > 1 and len(i) <= 1000 ]\n",
    "        \n",
    "        #if output is partition, we need to keep track of the full review\n",
    "        if output == 'partition':\n",
    "            full_review = ''\n",
    "        \n",
    "        #constituency parsers\n",
    "        \n",
    "        for rev in split_reviews:\n",
    "            if rev and rev.strip():\n",
    "                u = self.parser.parse(rev) # tree \n",
    "    \n",
    "                if type(u) == str:\n",
    "                    u = nltk.Tree.fromstring(u)\n",
    "    \n",
    "                for s in u.subtrees(): # subtrees \n",
    "                    if s.label() == 'S': # if sentence\n",
    "                        treelist += [s]\n",
    "                        lenlist += [len(s.leaves())] # how long clause\n",
    "                            \n",
    "                if output == 'partition':\n",
    "                    full_review += ' '.join(u.leaves()) + ' '\n",
    "    \n",
    "        treelist = [x for _, x in sorted(zip(lenlist,treelist),reverse=False)] # sort by lenlisit\n",
    "        clauses = [' '.join(tree.leaves()) for tree in treelist]\n",
    "        \n",
    "        #If there is no sentences detected, then the full review is the only clause.\n",
    "        if not clauses:\n",
    "            if output == 'partition':\n",
    "                clauses.append(full_review)\n",
    "            else:\n",
    "                clauses.append(review)\n",
    "        entity_with_clause = []\n",
    "        \n",
    "        if output == 'all':\n",
    "            for entity in entities:\n",
    "                clauselist = []\n",
    "                for clause in clauses:\n",
    "                    if entity in clause:\n",
    "                        clauselist.append(clause)\n",
    "                entity_with_clause.append((entity,clauselist))\n",
    "        \n",
    "        #TODO: create rules and test them\n",
    "        elif output == 'minimum':\n",
    "            for entity in entities:\n",
    "                for clause in clauses:\n",
    "                    if entity in clause:\n",
    "                        entity_with_clause.append((entity,clause))\n",
    "                        break\n",
    "                        \n",
    "        elif output == 'partition':\n",
    "            #first find minimal clause\n",
    "            for entity in entities:\n",
    "                for clause in clauses:\n",
    "                    if entity in clause:\n",
    "                        entity_with_clause.append((entity,clause))\n",
    "                        break\n",
    "            #get location of minimal clause in review\n",
    "            \n",
    "            entity_with_clause = self.join_partitions(full_review,entity_with_clause)\n",
    "        \n",
    "        return entity_with_clause\n",
    "    \n",
    "    \n",
    "    def dependency_tree(self, review, entities, output = 'split_min'):\n",
    "        #possible output = split_min, split_all, tree_min, tree_all -> split only uses sentence splitter, while tree takes into account tree structure\n",
    "        doc = self.parser(review)\n",
    "        \n",
    "        if output == 'split_min' or output == 'split_all' or output == 'split_part':\n",
    "            clauses = list(doc.sents)\n",
    "        #length of every clause\n",
    "        \n",
    "        lenlist = [len(str(x)) for x in clauses]\n",
    "            \n",
    "        #sort\n",
    "        clauses = [str(x) for _, x in sorted(zip(lenlist,clauses),reverse=False)]\n",
    "        \n",
    "        \n",
    "        entity_with_clause = []\n",
    "        \n",
    "        if output == 'split_min':\n",
    "            for entity in entities:\n",
    "                for clause in clauses:\n",
    "                    if entity in clause:\n",
    "                        entity_with_clause.append((entity,clause))\n",
    "                        break\n",
    "                        \n",
    "        if output == 'split_all':\n",
    "            for entity in entities:\n",
    "                clauselist = []\n",
    "                for clause in clauses:\n",
    "                    if entity in clause:\n",
    "                        clauselist.append(clause)\n",
    "                entity_with_clause.append((entity,clauselist))\n",
    "        \n",
    "        if output == 'split_part':\n",
    "            for entity in entities:\n",
    "                for clause in clauses:\n",
    "                    if entity in clause:\n",
    "                        entity_with_clause.append((entity,clause))\n",
    "                        break\n",
    "            #get location of minimal clause in review\n",
    "            \n",
    "            entity_with_clause = self.join_partitions(review,entity_with_clause)\n",
    "                \n",
    "        \n",
    "        return(entity_with_clause)\n",
    "\n",
    "\n",
    "    def vader_sentiment(self, entity_with_clause):\n",
    "        analyzer = SentimentIntensityAnalyzer()\n",
    "        entity_with_sentiment = []\n",
    "        for entity, clause in entity_with_clause:\n",
    "            sentiment = analyzer.polarity_scores(clause)['compound']\n",
    "            entity_with_sentiment.append((entity,sentiment))\n",
    "        return(entity_with_sentiment)   \n",
    "\n",
    "\n",
    "    def sentiment_analysis(self, entity_with_review, \n",
    "                           sentiment_package = 'stanford'):\n",
    "        #takes in list of tuples\n",
    "        if sentiment_package == 'stanford':\n",
    "            return stanford_sentiment(entity_with_review)\n",
    "        elif sentiment_package == 'vader':\n",
    "            return self.vader_sentiment(entity_with_review)\n",
    "        else:\n",
    "            raise Exception('incorrect sentiment package')\n",
    "\n",
    "\n",
    "    def sentiment_analysis_indiv(self, clause,sentiment_package = 'stanford'):\n",
    "        #takes in a single review\n",
    "        if sentiment_package == 'stanford':\n",
    "            stanford_sentiment_start()\n",
    "            result = nlp.annotate(clause,\n",
    "                       properties={\n",
    "                           'annotators': 'sentiment',\n",
    "                           'outputFormat': 'json'\n",
    "                       })\n",
    "            return np.dot(result['sentences'][0]['sentimentDistribution'], [-2, -1, 0, 1, 2])\n",
    "        elif sentiment_package == 'vader':\n",
    "            analyzer = SentimentIntensityAnalyzer()\n",
    "            return analyzer.polarity_scores(clause)['compound']\n",
    "        else:\n",
    "            raise Exception('incorrect sentiment package')\n",
    "\n",
    "    \n",
    "    def rule_1(self, review, entities):\n",
    "        entity_with_review = self.min_tree(review, entities, output = 'minimum')\n",
    "        entity_with_sentiment = self.sentiment_analysis(entity_with_review, \n",
    "                                                        self.sentiment_package)\n",
    "        return entity_with_sentiment\n",
    "    \n",
    "    \n",
    "    def rule_2(self, review, entities):\n",
    "        entity_with_review = self.min_tree(review, entities, output = 'all')\n",
    "        entity_with_sentiment = []\n",
    "        sentiment = 0\n",
    "        for ent, revlist in entity_with_review:\n",
    "            for clause in revlist:\n",
    "                sentiment = self.sentiment_analysis_indiv(clause,self.sentiment_package)\n",
    "                if self.sentiment_package == 'vader' and sentiment != 0:\n",
    "                    break\n",
    "                elif self.sentiment_package == 'stanford' and abs(sentiment) > 0.5:\n",
    "                    break\n",
    "                    #if sentiment is not neutral, stop. If sentiment is neutral, keep going up tree.                    \n",
    "            entity_with_sentiment.append((ent,sentiment))\n",
    "        return entity_with_sentiment\n",
    "    \n",
    "    \n",
    "    def rule_3(self, review, entities):\n",
    "        entity_with_review = self.min_tree(review, entities, output = 'all')\n",
    "        \n",
    "        entity_with_sentiment = []\n",
    "        for ent, revlist in entity_with_review:\n",
    "            sentiment_list = []\n",
    "            for clause in revlist:\n",
    "                sentiment = self.sentiment_analysis_indiv(clause,self.sentiment_package)\n",
    "                sentiment_list.append(sentiment)\n",
    "            if not sentiment_list:\n",
    "                sentiment_list.append(0)\n",
    "            entity_with_sentiment.append((ent,np.mean(sentiment_list)))\n",
    "        \n",
    "        return entity_with_sentiment\n",
    "    \n",
    "    \n",
    "    def rule_4(self, review, entities):\n",
    "        entity_with_review = self.min_tree(review, entities, output = 'partition')\n",
    "        entity_with_sentiment = self.sentiment_analysis(entity_with_review, self.sentiment_package)\n",
    "        return entity_with_sentiment\n",
    "    \n",
    "    \n",
    "    def rule_5(self, review, entities):\n",
    "        entity_with_review = self.min_tree(review, entities, output = 'minimum')\n",
    "        entity_with_review_p = self.min_tree(review, entities, output = 'partition')\n",
    "        \n",
    "        entity_with_sentiment = self.sentiment_analysis(entity_with_review, self.sentiment_package)\n",
    "        for i in range(len(entity_with_sentiment)):\n",
    "            sent = entity_with_sentiment[i][1]\n",
    "            if self.sentiment_package == 'vader' and sent != 0:\n",
    "                entity_with_sentiment[i] = (entity_with_sentiment[i][0],\n",
    "                                            self.sentiment_analysis_indiv(entity_with_review_p[i][1],\n",
    "                                                                          self.sentiment_package))\n",
    "            elif self.sentiment_package == 'stanford' and abs(sent) > 0.5:\n",
    "                entity_with_sentiment[i] = (entity_with_sentiment[i][0],\n",
    "                                            self.sentiment_analysis_indiv(entity_with_review_p[i][1],\n",
    "                                                                          self.sentiment_package))\n",
    "    \n",
    "        return entity_with_sentiment\n",
    "    \n",
    "    \n",
    "    def rule_6(self, review, entities):\n",
    "        entity_with_review = self.min_tree(review, entities, output = 'no_parse')\n",
    "        return entity_with_review\n",
    "    \n",
    "    def rule_7(self, review, entities):\n",
    "        self.parser = spacy.load(\"en_core_web_sm\")\n",
    "        entity_with_review = self.dependency_tree(review, entities, output = 'split_min')\n",
    "        entity_with_sentiment = self.sentiment_analysis(entity_with_review, \n",
    "                                                        self.sentiment_package)\n",
    "        return entity_with_sentiment\n",
    "    \n",
    "    def rule_8(self, review, entities):\n",
    "        self.parser = spacy.load(\"en_core_web_sm\")\n",
    "        \n",
    "        entity_with_review = self.dependency_tree(review, entities, output = 'split_all')\n",
    "        new_entity_with_review = []\n",
    "        entity_with_sentiment = []\n",
    "        sentiment = 0\n",
    "        for ent, revlist in entity_with_review:\n",
    "            for clause in revlist:\n",
    "                sentiment = self.sentiment_analysis_indiv(clause,self.sentiment_package)\n",
    "                if self.sentiment_package == 'vader' and sentiment != 0:\n",
    "                    new_entity_with_review.append((ent,clause))\n",
    "                    break\n",
    "                elif self.sentiment_package == 'stanford' and abs(sentiment) > 0.5:\n",
    "                    new_entity_with_review.append((ent,clause))\n",
    "                    break\n",
    "                    #if sentiment is not neutral, stop. If sentiment is neutral, keep going up tree.                    \n",
    "            entity_with_sentiment.append((ent,sentiment))\n",
    "            \n",
    "        entity_with_review = new_entity_with_review\n",
    "        entity_with_sentiment = self.sentiment_analysis(entity_with_review, \n",
    "                                                        self.sentiment_package)\n",
    "        return entity_with_sentiment \n",
    "        \n",
    "    def rule_9(self, review, entities):\n",
    "        self.parser = spacy.load(\"en_core_web_sm\")\n",
    "        \n",
    "        entity_with_review = self.dependency_tree(review, entities, output = 'split_min')\n",
    "        entity_with_review_p = self.dependency_tree(review, entities, output = 'split_part')\n",
    "        \n",
    "        entity_with_sentiment = self.sentiment_analysis(entity_with_review, self.sentiment_package)\n",
    "        for i in range(len(entity_with_sentiment)):\n",
    "            sent = entity_with_sentiment[i][1]\n",
    "            if self.sentiment_package == 'vader' and sent != 0:\n",
    "                entity_with_review[i] = entity_with_review_p[i]\n",
    "            elif self.sentiment_package == 'stanford' and abs(sent) > 0.5:\n",
    "                entity_with_review[i] = entity_with_review_p[i]\n",
    "                \n",
    "        return entity_with_review\n",
    "    \n",
    "    \n",
    "    \n",
    "    def kill_host(self):\n",
    "        if self.sentiment_package == \"stanford\":\n",
    "            self.parser.kill_host()\n",
    "        else:\n",
    "            print(\"Stanford server not initialized\")\n",
    "            \n",
    "            \n",
    "    def get_entities(self, text):\n",
    "        \"\"\"\n",
    "        Input nlp_model and text, retrieve a list of unique entities from the text.\n",
    "        \"\"\"\n",
    "        doc = self.nlp(text)\n",
    "        entities = set()\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"PRODUCT\":\n",
    "                entities.add(ent.text)\n",
    "        return list(entities)\n",
    "    \n",
    "    \n",
    "    def _parallelize_default(self, review):\n",
    "        entities = self.get_entities(review)    \n",
    "        result = self.rule_2(review, entities)\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def parallelize_predict(self, input_data):\n",
    "        input_data = self.assert_list_form(input_data)\n",
    "        entities_with_sentiment = Parallel(n_jobs=self.num_cores)(delayed(self._parallelize_default)(i) for i in input_data)\n",
    "        return entities_with_sentiment\n",
    "    \n",
    "    # default using rule 2 for prediction\n",
    "    def defaultPredict(self, input_data):\n",
    "        entities_with_sentiment = []\n",
    "\n",
    "        input_data = self.assert_list_form(input_data)\n",
    "\n",
    "        for review in tqdm(input_data):\n",
    "            entities = self.get_entities(review)    \n",
    "            result = self.rule_2(review, entities)\n",
    "            entities_with_sentiment.append(result)\n",
    "        return entities_with_sentiment\n",
    "        \n",
    "    def assert_list_form(self, input_data):\n",
    "        if not isinstance(input_data, list):\n",
    "            input_data = [input_data]\n",
    "\n",
    "        assert isinstance(input_data, list)\n",
    "        assert isinstance(input_data[0], str) \n",
    "\n",
    "        return input_data\n",
    "    \n",
    "    def customPredict(self, input_data, rule_number=2):\n",
    "        entities_with_sentiment = []\n",
    "\n",
    "        input_data = self.assert_list_form(input_data)\n",
    "\n",
    "        for review in input_data:\n",
    "            entities = self.get_entities(review)\n",
    "            if rule_number == 1:\n",
    "                result = self.rule_1(review, entities)\n",
    "            elif rule_number == 2:\n",
    "                result = self.rule_2(review, entities)\n",
    "            elif rule_number == 3:\n",
    "                result = self.rule_3(review, entities)\n",
    "            elif rule_number == 4:\n",
    "                result = self.rule_4(review, entities)\n",
    "            elif rule_number == 5:\n",
    "                result = self.rule_5(review, entities)\n",
    "            elif rule_number == 6:\n",
    "                result = self.rule_6(review, entities)\n",
    "            elif rule_number == 7:\n",
    "                result = self.rule_7(review, entities)\n",
    "            elif rule_number == 8:\n",
    "                result = self.rule_8(review, entities)\n",
    "            elif rule_number == 9:\n",
    "                result = self.rule_9(review, entities)\n",
    "            else:\n",
    "                raise Exception('Rule number invalid, please choose something between 1 and 9')\n",
    "                \n",
    "            entities_with_sentiment.append(result)\n",
    "            \n",
    "        return entities_with_sentiment\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy validation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"spacy_validate.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1KTr0oUxy27VOldpmjxfs-zf5nGwIwmaf\n",
    "\"\"\"\n",
    "from __future__ import unicode_literals, print_function\n",
    "import ast \n",
    "import plac\n",
    "import random\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "import time\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "def create_train_data(df):\n",
    "    train_data = []\n",
    "    newnlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        doc = newnlp(df['text'].iloc[i])\n",
    "        entity_list = df['entities_clean'].iloc[i]\n",
    "        for ent in doc.ents:\n",
    "            entity_list.append((ent.start_char, ent.end_char, ent.label_))\n",
    "            entity_dict = {\"entities\": entity_list}\n",
    "            train_data.append((df['text'].iloc[i], entity_dict))\n",
    "    return train_data\n",
    "\n",
    "def create_test_data(df):\n",
    "    test_data = []\n",
    "    newnlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        doc = newnlp(df['text'].iloc[i])\n",
    "        entity_list = df['entities_clean'].iloc[i]\n",
    "        for ent in doc.ents:\n",
    "            entity_list.append((ent.start_char, ent.end_char, ent.label_))\n",
    "        entity_dict = {\"entities\": entity_list}\n",
    "        test_data.append((df['text'].iloc[i], entity_dict))\n",
    "    return test_data\n",
    "\n",
    "def create_masked_train_data(df, masked_entities):\n",
    "    train_data = []\n",
    "    newnlp = spacy.load(\"en_core_web_sm\")\n",
    "  \n",
    "    for i in range(len(df)):\n",
    "        doc = newnlp(df['text'].iloc[i])\n",
    "        entity_list = df['entities_clean'].iloc[i]\n",
    "        for ent in doc.ents:\n",
    "            if ent.text not in masked_entities:\n",
    "                entity_list.append((ent.start_char, ent.end_char, ent.label_))\n",
    "        entity_dict = {\"entities\": entity_list}\n",
    "        train_data.append((df['text'].iloc[i], entity_dict))\n",
    "    return train_data\n",
    "\n",
    "def masked_train_test(train, test):\n",
    "    brand_list = []\n",
    "    for (index,entity_loc) in enumerate(train['entities_clean']):\n",
    "        text = train['text'].iloc[index]\n",
    "        for pair in entity_loc:\n",
    "            brand_list.append(text[pair[0]:pair[1]])\n",
    "      \n",
    "    import numpy as np\n",
    "    unique_brands = np.unique(brand_list)\n",
    "\n",
    "    newbrand_list = []\n",
    "    for (index, entity_loc) in enumerate(test['entities_clean']):\n",
    "        text = test['text'].iloc[index]\n",
    "        for pair in entity_loc:\n",
    "            newbrand_list.append(text[pair[0]:pair[1]])\n",
    "      \n",
    "    import numpy as np\n",
    "    newunique_brands = np.unique(newbrand_list)\n",
    "\n",
    "    in_common = list(set(unique_brands) & set(newunique_brands))\n",
    "    print(\"Total in common:\",len(in_common))\n",
    "\n",
    "    masked_entities, unmasked_entities = train_test_split(in_common, test_size = .5)\n",
    "    print(\"Total masked:\", len(masked_entities))\n",
    "\n",
    "    # new entity label\n",
    "    TRAIN_DATA = create_masked_train_data(train, masked_entities)\n",
    "    TEST_DATA = create_test_data(test)\n",
    "    return TRAIN_DATA, TEST_DATA, masked_entities, unique_brands, newunique_brands\n",
    "\n",
    "def evaluate_novelty(trained_model, masked_train_data, masked_test_data, masked_entities, unmasked_train_data, unmasked_test_data):\n",
    "    nomask_true = {}\n",
    "    nomask = {}\n",
    "\n",
    "    for review in unmasked_test_data:\n",
    "        test_ents_true = [review[0][start:end] for (start, end, label) in review[1]['entities']]\n",
    "        doc = trained_model(review[0])\n",
    "        test_ents = [ent.text for ent in doc.ents]\n",
    "\n",
    "        for entity in masked_entities:\n",
    "            if entity in test_ents_true: \n",
    "                if (entity in test_ents):\n",
    "                    if entity in nomask.keys():\n",
    "                        nomask[entity] += 1\n",
    "                        nomask_true[entity] +=1\n",
    "                    else: nomask_true[entity] = 0; nomask[entity]=0\n",
    "                elif entity in nomask_true.keys(): nomask_true[entity]+=1\n",
    "                else: nomask_true[entity] = 0\n",
    "\n",
    "    mask_true = {}\n",
    "    mask = {}\n",
    "\n",
    "    for review in masked_test_data:\n",
    "        test_ents_true = [review[0][start:end] for (start, end, label) in review[1]['entities']]\n",
    "        doc = trained_model(review[0])\n",
    "        test_ents = [ent.text for ent in doc.ents]\n",
    "\n",
    "    for entity in masked_entities:\n",
    "        if entity in test_ents_true: \n",
    "            if (entity in test_ents):\n",
    "                if entity in mask.keys():\n",
    "                    mask[entity] += 1\n",
    "                    mask_true[entity] +=1\n",
    "                else: mask_true[entity] = 0; mask[entity]=0\n",
    "            elif entity in mask_true.keys(): mask_true[entity]+=1\n",
    "            else: mask_true[entity] = 0\n",
    "\n",
    "    ratios_without_mask = {}\n",
    "    for key in nomask.keys():\n",
    "        if nomask_true[key] !=0:\n",
    "            ratios_without_mask[key] = nomask[key]/nomask_true[key]\n",
    "    ratios = {}\n",
    "    for key in mask.keys():\n",
    "        if mask_true[key] !=0:\n",
    "            ratios[key] = mask[key]/mask_true[key]\n",
    "\n",
    "    difference = {}\n",
    "    for keys in ratios_without_mask:\n",
    "        difference[keys] =  ratios[keys] - ratios_without_mask[keys]\n",
    "    return difference, ratios, ratios_without_mask\n",
    "\n",
    "def evaluate_spacy(trained_model_dir='../workspace/models/er_model', dataset_path=\"../workspace/data/test.csv\", verbose=True):\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    df['entities_clean']=[ast.literal_eval(i) for i in df['entities']]\n",
    "    train_df, test_df = train_test_split(df, test_size = .2)\n",
    "    trained_model = spacy.load(trained_model_dir)\n",
    "    LABEL = \"PRODUCT\"\n",
    "    masked_TRAIN_DATA, masked_TEST_DATA, masked_entities, unique_brands, newunique_brands = masked_train_test(train_df, test_df)\n",
    "\n",
    "    TRAIN_DATA = create_train_data(train_df)\n",
    "    TEST_DATA = create_test_data(test_df)\n",
    "\n",
    "    difference, ratios, ratios_without_mask = evaluate_novelty(trained_model, masked_TRAIN_DATA,masked_TEST_DATA,masked_entities, TRAIN_DATA,TEST_DATA)\n",
    "    if verbose == True:\n",
    "        print('DIFFERENCES')\n",
    "        print(difference)\n",
    "        print('RATIOS WITH MASK')\n",
    "        print(ratios)\n",
    "        print('RATIOS WITHOUT MASK')\n",
    "        print(ratios_without_mask)\n",
    "    d = {'difference': difference, 'ratios with mask':ratios,'ratios without mask': ratios_without_mask}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running End-to-End Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of businesses in subset:  142\n",
      "Number of businesses with 3.5-4.5 stars:  57\n"
     ]
    }
   ],
   "source": [
    "# GET ALL RESTAURANTS \n",
    "\n",
    "# import data\n",
    "df_raw = pd.read_json(\"../data/restaurant_reviews_1900k.json\", lines=True)\n",
    "\n",
    "# only get restaurants with many reviews\n",
    "many_reviews = df_raw[['business_id','review_id']].groupby(\"business_id\")['review_id'].nunique()\n",
    "many_reviews = many_reviews[many_reviews > 1000].index # more than 100 reviews\n",
    "df = df_raw[df_raw.business_id.isin(set(many_reviews))]\n",
    "print(\"Number of businesses in subset: \", len(df.business_id.unique()))\n",
    "\n",
    "# only grab restaurants with 3-4 stars\n",
    "business_stars = df[['business_id', 'stars']].groupby('business_id').mean()\n",
    "business_ids_similar_stars= business_stars[\n",
    "    (business_stars.stars >= 3.0) \n",
    "    & (business_stars.stars <= 4.0)].index\n",
    "\n",
    "print(\"Number of businesses with 3.5-4.5 stars: \", len(business_ids_similar_stars.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus = df[df.business_id.isin(set(business_ids_similar_stars[:50]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "brandlist = pd.read_csv('../workspace/data/wordnet_food_beverages_list.csv', header=None, names=['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = bus\n",
    "business_ids_similar_stars = bus.business_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> GENERATING DATASETS FOR TRAINING YOUR MODEL\n",
      "   ===> CONVERTING DATA FOR SPACY\n",
      "LENGTH OF DATASET:  500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54879b6665d34d0e9cd11967ea7d82c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   ===> SPLITTING INTO TRAIN/VALIDATION/TEST SETS\n",
      "==> DATASETS GENERATED\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                  review_id  \\\n",
       " 370  pC3M0xsaafKfI9sD5uiXeA   \n",
       " 172  Y13MHKqcUuZ95Todym7UhQ   \n",
       " 399  fwTB59IqvAKpCLMHOebhbg   \n",
       " 473  KUPt55joo2oF_R2HFLWGKA   \n",
       " 171  XN0L-TuLnTsubW1r0tkRJg   \n",
       " ..                      ...   \n",
       " 300  rOOcSaZPyfhRpLl_rsZnmQ   \n",
       " 21   L-WvhgaQNout5Gnry9qOJQ   \n",
       " 387  tRSfW23atzUbAX17i-yl-Q   \n",
       " 433  8iAWlWJ5MSY6zPiY_8Tbaw   \n",
       " 167  eouLqsQakjGrxd2aiHGdAw   \n",
       " \n",
       "                                                   text  \\\n",
       " 370  I came here on New Year's Eve day with a coupl...   \n",
       " 172  the view was nice, the bed was ok, the bathroo...   \n",
       " 399  Expected better at Cosmo based on other restau...   \n",
       " 473  Great for breakfast on the Strip!  Not impress...   \n",
       " 171  We were in Vegas a month ago and stayed at the...   \n",
       " ..                                                 ...   \n",
       " 300  Worst customer service I've EVER experienced!!...   \n",
       " 21   The chicken is bland but the salmon is great t...   \n",
       " 387  Lo-Lo's is exactly the sort of place which exp...   \n",
       " 433  A cool spot to grab food and drinks in Downtow...   \n",
       " 167  I LOVE Tupelo. The staff is extremely friendly...   \n",
       " \n",
       "                                               entities  \n",
       " 370  [(1210, 1217, PRODUCT), (584, 588, PRODUCT), (...  \n",
       " 172                                [(52, 57, PRODUCT)]  \n",
       " 399  [(218, 225, PRODUCT), (344, 349, PRODUCT), (26...  \n",
       " 473  [(270, 274, PRODUCT), (849, 854, PRODUCT), (72...  \n",
       " 171  [(377, 384, PRODUCT), (686, 693, PRODUCT), (60...  \n",
       " ..                                                 ...  \n",
       " 300  [(1303, 1306, PRODUCT), (1303, 1312, PRODUCT),...  \n",
       " 21   [(4, 11, PRODUCT), (99, 104, PRODUCT), (184, 1...  \n",
       " 387  [(169, 176, PRODUCT), (449, 456, PRODUCT), (54...  \n",
       " 433  [(601, 608, PRODUCT), (877, 884, PRODUCT), (50...  \n",
       " 167  [(247, 254, PRODUCT), (115, 118, PRODUCT), (21...  \n",
       " \n",
       " [325 rows x 3 columns],                   review_id  \\\n",
       " 78   N0eOj_QopuJO1-5phc_dzQ   \n",
       " 411  FtnseB-wy9KGxpLfZTn-QQ   \n",
       " 27   vhBiW5dbzg9DPH0sdhU1tw   \n",
       " 125  c6XZQin9OARRnVkohAYmCg   \n",
       " 24   OSH5oSQACQTPcde_29vJDA   \n",
       " 54   qVJ-5JKWR5_qRgUQbRYI0g   \n",
       " 445  CC1ilOEpYjaESQd-bh6yBg   \n",
       " 144  LLsJh5tuWI3bY0oewyGOrA   \n",
       " 398  SBOPy_Fe1-dC2w5fC9n8kw   \n",
       " 188  _9RsaHpnpKEIIeXrs1ZoOA   \n",
       " 305  LGc5NzU5Qxh8YmtVSYiFrA   \n",
       " 396  Mxuyw6m3rht-3qYfzHUaXA   \n",
       " 239  oHYMJX5FkmXUUrSOrQroUA   \n",
       " 5    X71pWeyu4A05JGfhbnSW4g   \n",
       " 29   J8ChT049oxIt4CobzMmHFQ   \n",
       " 156  mOnebIXbxGQsP0Sd83KFVQ   \n",
       " 291  lOlJ2D0nhlhB6NO75my87g   \n",
       " 372  JomkymPiEUu9rCaJDDPRCw   \n",
       " 216  RwE0jqArmKX4XxEicWVVBQ   \n",
       " 189  IptjnzkUctENUZVt99oLWA   \n",
       " 289  Qb9epxaGjJoIXi5TlqL84A   \n",
       " 63   rF5SiT7X1R5lo3ywOETjsA   \n",
       " 405  we6OJJDB6GTB2xz_Xz6Wiw   \n",
       " 274  KOEIBP3AvlbWtPM4EVVXdw   \n",
       " 38   Coz0RgtHS40m75UnBb4e7A   \n",
       " 268  2cJlSVocjnLnXXdnyJmTjA   \n",
       " 402  MA-Vn2XlJgdbeBn6ijT6Bw   \n",
       " 51   5YP_d1RKpWrvahF4vmTxTw   \n",
       " 492  vdhslt75ArCuqp-dkBwv3Q   \n",
       " 236  edXx22FdwMJPZmmcqRXhyQ   \n",
       " 190  IwtA1Yqy5iAP51qSWGLKHA   \n",
       " 111  DL3NhfOml9vhzppyGdypEg   \n",
       " 19   0AKuRBuMkhvWvp05kGZ1Iw   \n",
       " 353  PTdAtSwoy2-hwepXapmH9Q   \n",
       " 3    T54tDAzQol8ahQeun34ZCg   \n",
       " 206  LvwxURYYVcRRZsA9AeNBZQ   \n",
       " 345  rkrUEBPwriI1axz_5oQyHw   \n",
       " 7    nrGlTvSjEs3rx3fpKO3uOA   \n",
       " 90   7MKHMu8_l2MKaxWtpaaPXw   \n",
       " 479  Hmgn6HKvlSfD83e4tdEgow   \n",
       " 391  _gs5ZKHQyM4O0XZFV1f9Vw   \n",
       " 389  fh4dp4wvaSHJKn9ZFryFeQ   \n",
       " 339  2Yi3KQA-u6Hc6Yf61UTPkA   \n",
       " 467  sU9cD3nwRfGFS0IU24iVTA   \n",
       " 193  8LCCiMLkFQ96ewJPbb84AA   \n",
       " 436  NEMgCJDhi5uTzAHw5Tni3Q   \n",
       " 126  LkLfaNDUjaIjbYPXE_lamw   \n",
       " 222  Jl5h57nYlT5QRz2p50iLgg   \n",
       " 123  jPGjiP1-1X43GgAtYJ4COg   \n",
       " 426  _mGOkORV_ioEhlCqutCC3A   \n",
       " \n",
       "                                                   text  \\\n",
       " 78   I've stayed at the Cosmopolitan 3x. Each time ...   \n",
       " 411  I love sitting at the bar and talking to the c...   \n",
       " 27   All the food here was good. I guess I was expe...   \n",
       " 125  I've eaten here a few time before but, never w...   \n",
       " 24   Amazing experience! The girl from the front de...   \n",
       " 54   Not bad, but just an over hyped, over priced S...   \n",
       " 445  Liked the mexibeni. Great change from a tradit...   \n",
       " 144  Food is good. It is kinda expensive. Service w...   \n",
       " 398  Fleur by Hubert Keller was one of the girlfrie...   \n",
       " 188  Holsteins was amazingly good. I had the Gold S...   \n",
       " 305  I'm giving this 3 stars for the popcorn and bi...   \n",
       " 396  Lavo was recommended as one of the new Vegas h...   \n",
       " 239  I been coming to Vegas for over 15 years... La...   \n",
       " 5    The additional Seafood Buffet $15 total of $47...   \n",
       " 29   This review is for the food only.\\n\\nService w...   \n",
       " 156  #11 of 2017\\n\\nThere are so many restaurants o...   \n",
       " 291  Ambiance -  5 stars (see Vero H.'s review. Als...   \n",
       " 372  Amazing seafood station and latin station, als...   \n",
       " 216  I only eat here when I stay in the Venetian ou...   \n",
       " 189  Terrible service. Good rooms and convenient bu...   \n",
       " 289  So first off I was the only person under 30 th...   \n",
       " 63   wish there were more then the 2 in las vegas t...   \n",
       " 405  Had the Irish cheesesteak and it blew my mind....   \n",
       " 274  Had dinner here Tuesday evening and it was ama...   \n",
       " 38   Only stopped in for a drink, but would definit...   \n",
       " 268  Our new favorite place in Vegas! Vintage Vegas...   \n",
       " 402  Never even got in.  I imagine with such a line...   \n",
       " 51   Breakfast here was decent - too much onion in ...   \n",
       " 492  You will literally drop your jaws when the foo...   \n",
       " 236  Great ambiance with a Palm Springs vibe for de...   \n",
       " 190  Food was good but could be better. I swear the...   \n",
       " 111  Ordered the corned beef hash with 3 basted egg...   \n",
       " 19   This place just didn't do it for me. We ate at...   \n",
       " 353  Soooooo... truth be told, we really wanted to ...   \n",
       " 3    Great spot, great food, great value. Had a cou...   \n",
       " 206  Interesting menu, with some good flavors.  Pim...   \n",
       " 345  This place has been on my bucket for a while, ...   \n",
       " 7    There are so many options in Las Vegas and I h...   \n",
       " 90   This is my first stop when I'm in Vegas for an...   \n",
       " 479  What is all the hype about this buffet? The \"s...   \n",
       " 391  This is my 2nd time to wicked spoon and I gott...   \n",
       " 389  Gross Gross Gross!!!!! DO NOT waste your money...   \n",
       " 339  3.5 sorta mini tao.  easy enough line (free pa...   \n",
       " 467  A welcome addition to a neighborhood in need o...   \n",
       " 193  I really like Guy Fieri, but I'm not a huge fa...   \n",
       " 436  Hometown Buffet ain't got nothing on Bacchanal...   \n",
       " 126  My very first experience at LoLos. I have to s...   \n",
       " 222  Was shown to our table where we waited for 1/2...   \n",
       " 123  Fantastic!  Hash browns were amazing breakfast...   \n",
       " 426  Just another tourist trap in Vegas. Shame on m...   \n",
       " \n",
       "                                               entities  \n",
       " 78   [(668, 675, PRODUCT), (350, 355, PRODUCT), (37...  \n",
       " 411  [(373, 380, PRODUCT), (150, 155, PRODUCT), (39...  \n",
       " 27   [(204, 214, PRODUCT), (8, 12, PRODUCT), (179, ...  \n",
       " 125  [(397, 404, PRODUCT), (144, 149, PRODUCT), (53...  \n",
       " 24                                                  []  \n",
       " 54   [(166, 169, PRODUCT), (115, 119, PRODUCT), (25...  \n",
       " 445                                [(52, 61, PRODUCT)]  \n",
       " 144  [(86, 90, PRODUCT), (105, 110, PRODUCT), (37, ...  \n",
       " 398  [(460, 464, PRODUCT), (1377, 1382, PRODUCT), (...  \n",
       " 188  [(270, 274, PRODUCT), (331, 335, PRODUCT), (72...  \n",
       " 305  [(53, 57, PRODUCT), (58, 63, PRODUCT), (75, 80...  \n",
       " 396  [(181, 185, PRODUCT), (324, 327, PRODUCT), (54...  \n",
       " 239  [(252, 257, PRODUCT), (114, 121, PRODUCT), (24...  \n",
       " 5    [(15, 22, PRODUCT), (232, 236, PRODUCT), (249,...  \n",
       " 29   [(351, 358, PRODUCT), (484, 489, PRODUCT), (39...  \n",
       " 156  [(882, 887, PRODUCT), (1107, 1112, PRODUCT), (...  \n",
       " 291  [(475, 479, PRODUCT), (239, 246, PRODUCT), (67...  \n",
       " 372  [(56, 60, PRODUCT), (166, 170, PRODUCT), (8, 1...  \n",
       " 216  [(298, 302, PRODUCT), (307, 316, PRODUCT), (97...  \n",
       " 189                                 [(9, 16, PRODUCT)]  \n",
       " 289  [(198, 201, PRODUCT), (303, 306, PRODUCT), (24...  \n",
       " 63                                 [(50, 55, PRODUCT)]  \n",
       " 405              [(57, 61, PRODUCT), (8, 13, PRODUCT)]  \n",
       " 274  [(198, 203, PRODUCT), (433, 440, PRODUCT), (47...  \n",
       " 38   [(278, 282, PRODUCT), (81, 88, PRODUCT), (66, ...  \n",
       " 268  [(17, 22, PRODUCT), (67, 71, PRODUCT), (33, 40...  \n",
       " 402            [(77, 82, PRODUCT), (98, 103, PRODUCT)]  \n",
       " 51   [(0, 9, PRODUCT), (244, 253, PRODUCT), (229, 2...  \n",
       " 492  [(439, 446, PRODUCT), (495, 502, PRODUCT), (56...  \n",
       " 236  [(118, 125, PRODUCT), (334, 341, PRODUCT), (60...  \n",
       " 190           [(69, 74, PRODUCT), (133, 137, PRODUCT)]  \n",
       " 111  [(19, 23, PRODUCT), (200, 207, PRODUCT), (83, ...  \n",
       " 19               [(5, 10, PRODUCT), (51, 61, PRODUCT)]  \n",
       " 353  [(384, 389, PRODUCT), (168, 172, PRODUCT), (23...  \n",
       " 3    [(86, 90, PRODUCT), (91, 95, PRODUCT), (79, 90...  \n",
       " 206  [(12, 16, PRODUCT), (117, 121, PRODUCT), (43, ...  \n",
       " 345  [(544, 548, PRODUCT), (267, 271, PRODUCT), (23...  \n",
       " 7    [(429, 432, PRODUCT), (740, 744, PRODUCT), (76...  \n",
       " 90   [(146, 153, PRODUCT), (48, 52, PRODUCT), (299,...  \n",
       " 479  [(45, 50, PRODUCT), (202, 210, PRODUCT), (277,...  \n",
       " 391                                                 []  \n",
       " 389           [(151, 156, PRODUCT), (57, 68, PRODUCT)]  \n",
       " 339                                                 []  \n",
       " 467  [(181, 186, PRODUCT), (281, 287, PRODUCT), (55...  \n",
       " 193  [(508, 513, PRODUCT), (581, 586, PRODUCT), (37...  \n",
       " 436              [(9, 15, PRODUCT), (62, 66, PRODUCT)]  \n",
       " 126  [(67, 74, PRODUCT), (107, 114, PRODUCT), (127,...  \n",
       " 222  [(17, 22, PRODUCT), (68, 75, PRODUCT), (202, 2...  \n",
       " 123  [(37, 46, PRODUCT), (12, 16, PRODUCT), (83, 88...  \n",
       " 426  [(206, 210, PRODUCT), (292, 296, PRODUCT), (17...  ,                   review_id  \\\n",
       " 17   lFfFHFBxGu_AGkj2heNaGg   \n",
       " 176  BDTlQRpQbze3yJI_P0cpCg   \n",
       " 313  YiYINkjrT4LOW72LXJyVjA   \n",
       " 365  1ShMVlTDrSPPvbe4gxkc0g   \n",
       " 164  CP_dPJ3_siyd3qkfXHpJAg   \n",
       " ..                      ...   \n",
       " 166  S6irOQQ6wxJVZPMmYDNLCA   \n",
       " 153  SGRFFmnFtK7DxZWkDk9Wzw   \n",
       " 169  yQPJ-qZXKxmL3k5-KhCDYg   \n",
       " 89   lpYY_25QdvFwROPTQpK_ng   \n",
       " 170  amhsRTUkG-iF6zCkQastMA   \n",
       " \n",
       "                                                   text  \\\n",
       " 17   Words cannot express how much I love this Pitt...   \n",
       " 176  Went to WS for New Years Eve and it was just o...   \n",
       " 313  Delicious food! Decent prices with plenty of o...   \n",
       " 365  I've been to Vegas so many times that it's no ...   \n",
       " 164  Sat at the bar for 10 minutes and never got lo...   \n",
       " ..                                                 ...   \n",
       " 166  Like the blackboard specials...good super whit...   \n",
       " 153  So underwhelming. Completely mediocre. Service...   \n",
       " 169  I dunno....I expected more.\\nI got in right be...   \n",
       " 89   You know it's going to be a good meal when you...   \n",
       " 170  Best hotel in Vegas! Super clean. Really over ...   \n",
       " \n",
       "                                               entities  \n",
       " 17                                                  []  \n",
       " 176  [(54, 58, PRODUCT), (195, 199, PRODUCT), (79, ...  \n",
       " 313  [(209, 215, PRODUCT), (129, 133, PRODUCT), (30...  \n",
       " 365  [(775, 782, PRODUCT), (829, 839, PRODUCT), (10...  \n",
       " 164                                [(74, 81, PRODUCT)]  \n",
       " ..                                                 ...  \n",
       " 166  [(91, 95, PRODUCT), (42, 47, PRODUCT), (79, 83...  \n",
       " 153  [(176, 180, PRODUCT), (234, 242, PRODUCT), (19...  \n",
       " 169  [(726, 733, PRODUCT), (583, 594, PRODUCT), (49...  \n",
       " 89   [(33, 37, PRODUCT), (120, 127, PRODUCT), (48, ...  \n",
       " 170                                                 []  \n",
       " \n",
       " [125 rows x 3 columns])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(reviews, brandlist, sample_size=500, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_ids_similar_stars = reviews.business_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> TRAINING YOUR SPACY MODEL!\n",
      "   ==> CONFIGURING FORMAT FOR SPACY TRAINING\n",
      "   ==> TRAINING...\n",
      "Loaded model 'en_core_web_sm'\n",
      "Total training time: 13.300416946411133\n",
      "Entities in 'Meh, not impressed with their selection.  Kind of sad when the most memorable part of the buffet was the gelato.  Crab legs served cold and pre sliced so you only get half the meat.  Prime rib was blah.  Worst part is only 2 stalls in the bathroom, very funny story while my friend and I occupied both stalls while making room for the next round of food, kid had to go really bad and was about to have an accident, so i thought i'd be nice and hurry it up, i told him to hold on and i'll be done shortly.  Then he started lipping off to me, i ended up taking my time... Lol!'\n",
      "PERSON Meh\n",
      "PRODUCT buffet\n",
      "PRODUCT gelato\n",
      "ORG Crab\n",
      "CARDINAL half\n",
      "PRODUCT meat\n",
      "CARDINAL only 2\n",
      "PRODUCT food\n",
      "Entities in 'We arrived yesterday at 12:30pm for a Sunday brunch, waited one hour to get in. They have raised prices on weekend brunch and charged us $39.99 + tax each at 1:32pm. Get a player's card to take $3 off each person. Only after we sit down, we've found out we are ripped off. The crab claws, lamb chop, rainbow roll, mussels, clam baskets and many dinner items are missing until after 3:30pm.  The sushi are not fresh and the oysters are weak. The better food is the snow crab legs and the Ginseng chicken. We finished our brunch about two hours later but we were too full to test all the dinner food. My photos are all taken on the better food served after 3:30pm.\n",
      "Pros:\n",
      "They defrost the snow crab legs for each individual with hot water.\n",
      "Oysters served after 3pm tastes fresh.\n",
      "The Ginseng chicken soup is heavily loaded with good stuff. A must try.\n",
      "The small sized deserts tastes good.\n",
      "Cons:\n",
      "The bbq pork ribs is tough and tastes terrible. The Chinese dim sum is mediocre. Hot and sour soup is thick and bland.\n",
      "The server never return to refill our drinks and let the plates pile up. No tips!\n",
      "Many hot dishes do not have labels, making it hard to tell what cooked food you are getting.\n",
      "Some hot food is difficult to get to because pots and pans are put inches from the lights.\n",
      "What you see is not what you get. They claim to serve 500+ items at the front desk but I counted much less. There is a large Alaskan king crab at the display window but they serve only medium size snow crab legs.\n",
      "Overall:\n",
      "Price:          1\n",
      "Food:          3 (Maybe a 4 if you find the real dinner food)\n",
      "Service:      1\n",
      "Ambience: 4\n",
      "\n",
      "I wonder if many of the previous reviews are fake or if management at this restaurant has fallen off a cliff.'\n",
      "DATE yesterday\n",
      "DATE Sunday\n",
      "TIME one hour\n",
      "MONEY 39.99\n",
      "CARDINAL 1:32pm\n",
      "MONEY 3\n",
      "PRODUCT crab\n",
      "PRODUCT dinner\n",
      "PRODUCT sushi\n",
      "PRODUCT food\n",
      "PRODUCT crab\n",
      "ORG Ginseng\n",
      "PRODUCT chicken\n",
      "TIME about two hours\n",
      "PRODUCT dinner\n",
      "PRODUCT food\n",
      "PRODUCT food\n",
      "PRODUCT crab\n",
      "CARDINAL 3\n",
      "ORG Ginseng\n",
      "PRODUCT chicken\n",
      "PRODUCT small\n",
      "PRODUCT pork\n",
      "NORP Chinese\n",
      "PRODUCT food\n",
      "PRODUCT food\n",
      "PRODUCT inches\n",
      "CARDINAL 500\n",
      "NORP Alaskan\n",
      "PRODUCT crab\n",
      "PRODUCT crab\n",
      "PRODUCT Price\n",
      "CARDINAL 1\n",
      "PRODUCT Food\n",
      "CARDINAL 3\n",
      "CARDINAL 4\n",
      "PRODUCT dinner\n",
      "PRODUCT food\n",
      "PRODUCT Service\n",
      "CARDINAL 1\n",
      "CARDINAL 4\n",
      "PRODUCT restaurant\n",
      "Entities in 'Every great American city, has places you must go to that are practically institutions. Primanti's is one of those places. I first learned about Primanti's while watching a show on the Food Network that highlighted famous food joints around the country. \n",
      "\n",
      "While I was visiting a friend in Pittsburgh a few years back, we made the trip to Primanti's. Due to their huge popularity in Pittsburgh, they now have multiple locations, they're even in PNC Park. We made sure to go to the original Primanti's. \n",
      "\n",
      "Nothing really complicated here. They serve basically sandwiches, but with a twist. Rather than have your fries, coleslaw and sandwich separate, they bring it all together within the sandwich. \n",
      "\n",
      "Naturally, you don't need to order of wings or onion rings with your sandwich. One sandwich will fill you up. Despite the fact tourists frequent the place, Primanti's has the feel of a neighborhood hangout. \n",
      "\n",
      "The waiter service was great. The wait for our sandwiches wasn't too long. They have beer on tap, mostly domestic. \n",
      "\n",
      "The pastrami sandwich I ordered did not disappoint. Not too fatty. The bread was just right. If I visit Pittsburgh again, I am going to make another stop at Primanti's.'\n",
      "NORP American\n",
      "PERSON Primanti\n",
      "ORDINAL first\n",
      "PERSON Primanti\n",
      "ORG the Food Network\n",
      "PRODUCT food\n",
      "GPE Pittsburgh\n",
      "DATE a few years\n",
      "PERSON Primanti\n",
      "GPE Pittsburgh\n",
      "GPE PNC Park\n",
      "PERSON Primanti\n",
      "PRODUCT sandwich\n",
      "PRODUCT sandwich\n",
      "CARDINAL One\n",
      "PRODUCT place\n",
      "PERSON Primanti\n",
      "PRODUCT neighborhood\n",
      "PRODUCT service\n",
      "PRODUCT sandwiches\n",
      "PRODUCT pastrami\n",
      "PRODUCT bread\n",
      "GPE Pittsburgh\n",
      "PERSON Primanti\n",
      "Entities in 'My wife and I made a jaunt up to Madison, and spent a significant part of Saturday at the Allen Centennial Garden, which I can't recommend highly enough.  They have an edible section of the garden, and also an herb garden, and there was a little sign directing people to \"Graze\" where the herbs are used in their cocktails. Sold!\n",
      "\n",
      "Actually, the \"10 Babcock Drive\" wasn't that good of a cocktail. It talked a big game about the herb infusions and an herb-tincture, so I was expecting to be blown away by a garden-fresh experience.  There was some aroma, but the overwhelming taste was lemon juice; I think they could do better on this one-- I know I could.\n",
      "\n",
      "We \"grazed\" our way through various appetizers including the pork buns, beet salad, and deviled eggs. Portions were on the small side, but tasty. \n",
      "\n",
      "So why 4 stars? Well, partly it was the ambience (extremely high ceilings, surprisingly cosmopolitan decor-- plus, feel under the seats for foam that helps keep the din to a dull roar), partly it was the company of my lovely wife, and maybe some of my satisfaction was sunstroke-based (I should have worn a hat at the garden), but actually I've got two words for you: pickle board. Somewhere recently, maybe Lucky Peach, I was reading about the rise in sort of \"vegetarian charcuterie\". I scoffed, because to me charcuterie means meat, and it's sacrilegious to say otherwise, but some of those photos looked pretty fun, I *do* like pickled daikon, and I've found lately with charcuterie boards that I can have some vicious heartburn afterwards, so I figured I'd best keep an open mind.\n",
      "\n",
      "After having had several fairly small plates, we were pleasantly surprised to find ample portions of each of the half-dozen pickled vegetables.  All were uniquely tasty, with different levels and different types of brine.  My wife declared that she was full after a couple nibbles from each plate, but then couldn't stop picking up her chopsticks to get more. Highlights of the board included the earthy and spicy kim-chee, and the pickled ramps, which were crisp, sweet, and tangy. My wife finished those off.\n",
      "\n",
      "It was a little pricey, but we had a great time, and I'd definitely go back.  Maybe next time we'll take a stab at the $21, Rachel Ray approved, burger ...'\n",
      "PERSON Madison\n",
      "DATE Saturday\n",
      "FAC the Allen Centennial Garden\n",
      "PERSON Graze\n",
      "PRODUCT Sold\n",
      "CARDINAL 10\n",
      "PRODUCT cocktail\n",
      "PRODUCT herb\n",
      "PRODUCT juice\n",
      "PRODUCT pork\n",
      "PRODUCT buns\n",
      "PRODUCT salad\n",
      "PRODUCT side\n",
      "CARDINAL 4\n",
      "CARDINAL two\n",
      "PERSON Lucky Peach\n",
      "PRODUCT rise\n",
      "PRODUCT charcuterie\n",
      "PRODUCT daikon\n",
      "PRODUCT charcuterie\n",
      "CARDINAL half\n",
      "PRODUCT board\n",
      "PRODUCT earthy\n",
      "PRODUCT sweet\n",
      "PRODUCT pricey\n",
      "MONEY 21\n",
      "PERSON Rachel Ray\n",
      "Entities in 'Definitely the largest suites in Vegas with comfy beds and fantabulous service, perfect for the party. This is the place to bring large groups of animals. \n",
      "\n",
      "Large rooms to invite the random group of people to party with you, good service and location next to everything in the middle of the strip. Venetian, you never let me down- never disappoint. TAO is awesome, and convenient, cool people and great music.  \n",
      "\n",
      "Ladies, make sure to stay here next time your in vegas because I'll be going to a couple more bachelor parties this year. Great for anniversaries, bachelor party weekends, or weekend getaways with your friends.The best part about this place is that the pool is open late, and they also have great food for those drunken nights.\n",
      "\n",
      "Come here!!!'\n",
      "GPE Vegas\n",
      "PRODUCT service\n",
      "PRODUCT party\n",
      "PRODUCT place\n",
      "PRODUCT service\n",
      "ORG Venetian\n",
      "ORG TAO\n",
      "PRODUCT Ladies\n",
      "PRODUCT bachelor\n",
      "DATE this year\n",
      "DATE weekend\n",
      "PRODUCT place\n",
      "PRODUCT food\n",
      "PRODUCT drunken\n",
      "Entities in 'Quick spot to get lunch during the Conf Cobb salad with Margarita'\n",
      "ORG Conf Cobb\n",
      "PRODUCT salad\n",
      "ORG Margarita\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities in 'This place was great. We shared the bone marrow, gravy frites, and wild mushroom sardi. It was all amazing and the three dishes filled the two of us up. But, of course we had room for dessert as well and had the salted caramel pot de crme and an apple based dessert (called haystack) - they were equally amazing. We didn't have any drinks, but the wine menu had some reasonably priced house wines by the glass (and then some extremely expensive glasses and bottles for those of you looking to splurge). It's a little hipster-y (weird VHS fetish, I guess), but that didn't distract from the phenomenal meal.'\n",
      "PRODUCT place\n",
      "CARDINAL three\n",
      "CARDINAL two\n",
      "PRODUCT wine\n",
      "PRODUCT menu\n",
      "PRODUCT glass\n",
      "PRODUCT fetish\n",
      "PRODUCT phenomenal\n",
      "PRODUCT meal\n",
      "Entities in 'We found this place to be better than Caesars Palace based on the price. Best thing about the buffet was the fresh seafood cooked with wine. Worst thing was their pad Thai and Asian food selections, they were very dry.'\n",
      "PRODUCT place\n",
      "ORG Caesars Palace\n",
      "PRODUCT price\n",
      "PRODUCT buffet\n",
      "PRODUCT seafood\n",
      "NORP Thai\n",
      "NORP Asian\n",
      "PRODUCT food\n",
      "Entities in 'This place is definitely not over hyped! We ordered stupid fries, mac and cheese and the #3 and shared it all. Everything was so delicious! I highly recommend the mac and cheese! Kool-Aid to drink of course!'\n",
      "PRODUCT place\n",
      "PRODUCT cheese\n",
      "MONEY 3\n",
      "PRODUCT mac\n",
      "PRODUCT cheese\n",
      "PERSON Kool-Aid\n",
      "Entities in 'Good menu and good ambience. They serve everyone a biscuit with jam and honey when you first get there- I love that!\n",
      "\n",
      "I got their sweet potato pancakes with fried chicken on top- this is a dish for two people! I ate all the chicken and the baked apple was good with the bacon, but I could only eat one of the pancakes. Everything was good, the chicken was juicy and crispy, and the bacon was not too greasy. The baked apple added a nice tartness and lightness to the whole dish. One thing I appreciated- they actually made my eggs over medium!!! This is a rarity and I commend the chef for making my eggs a perfect medium, thank you!!!'\n",
      "PRODUCT menu\n",
      "ORDINAL first\n",
      "PRODUCT sweet\n",
      "PRODUCT potato\n",
      "PRODUCT chicken\n",
      "PRODUCT dish\n",
      "CARDINAL two\n",
      "PRODUCT chicken\n",
      "PRODUCT bacon\n",
      "CARDINAL one\n",
      "PRODUCT chicken\n",
      "PRODUCT bacon\n",
      "PRODUCT baked\n",
      "PRODUCT dish\n",
      "CARDINAL One\n",
      "PRODUCT chef\n",
      "Saved model to ..\\workspace\\models\\er_model\n",
      "Loading from ..\\workspace\\models\\er_model\n",
      "PRODUCT menu\n",
      "ORDINAL first\n",
      "PRODUCT sweet\n",
      "PRODUCT potato\n",
      "PRODUCT chicken\n",
      "PRODUCT dish\n",
      "CARDINAL two\n",
      "PRODUCT chicken\n",
      "PRODUCT bacon\n",
      "CARDINAL one\n",
      "PRODUCT chicken\n",
      "PRODUCT bacon\n",
      "PRODUCT baked\n",
      "PRODUCT dish\n",
      "CARDINAL One\n",
      "PRODUCT chef\n"
     ]
    }
   ],
   "source": [
    "# Train spacy model\n",
    "main_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spacy model\n",
    "nlp = spacy.load('..\\workspace\\models\\er_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                   | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on restaurant  d_L-rfS1vT3JMzgCUGtiow ...\n",
      "Number of Reviews left after subset length:  679\n",
      "Extracting entities from each review...\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n",
      "Rankings result: \n",
      "        entity  average_stars  predicted_score\n",
      "0         food       3.826979         0.458791\n",
      "1      service       3.904552         0.512331\n",
      "2      chicken       3.864151         0.275812\n",
      "3         menu       4.064815         0.293297\n",
      "4         meal       3.812081         0.352053\n",
      "5   restaurant       3.730858         0.192609\n",
      "6        place       3.782772         0.431067\n",
      "7        salsa       3.706849         0.477248\n",
      "8         fish       3.533333         0.204552\n",
      "9       dinner       3.873874         0.258615\n",
      "10       staff       4.046512         0.546689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|                                       | 1/50 [01:55<1:34:33, 115.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation Score:  0.36363636363636365\n",
      "Running on restaurant  N0apJkxIem2E8irTBRKnHw ...\n",
      "Number of Reviews left after subset length:  711\n",
      "Extracting entities from each review...\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|                                      | 2/50 [03:57<1:34:00, 117.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rankings result: \n",
      "        entity  average_stars  predicted_score\n",
      "0      service       3.959103         0.554775\n",
      "1         food       3.888521         0.465200\n",
      "2        place       3.937050         0.377412\n",
      "3         menu       4.026415         0.360981\n",
      "4       dinner       4.055351         0.357749\n",
      "5        price       3.785530         0.380288\n",
      "6        pizza       3.904573         0.324784\n",
      "7   restaurant       3.865784         0.378223\n",
      "8        staff       4.228571         0.517056\n",
      "9        pasta       3.835979         0.340938\n",
      "10      burger       3.974747         0.384439\n",
      "11      cheese       4.008451         0.239517\n",
      "12        meal       3.955556         0.367396\n",
      "13     chicken       3.959375         0.311633\n",
      "14       salad       3.980769         0.331614\n",
      "Spearman Correlation Score:  -0.11785714285714284\n",
      "Running on restaurant  IMLrj2klosTFvPRLv56cng ...\n",
      "Number of Reviews left after subset length:  679\n",
      "Extracting entities from each review...\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|                                     | 3/50 [05:52<1:31:27, 116.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rankings result: \n",
      "        entity  average_stars  predicted_score\n",
      "0       cheese       3.900000         0.307647\n",
      "1      service       3.901774         0.498638\n",
      "2        place       3.953243         0.515510\n",
      "3        decor       4.022388         0.594902\n",
      "4         food       3.883984         0.529409\n",
      "5   restaurant       3.853608         0.389117\n",
      "6     sandwich       3.978541         0.341135\n",
      "7      chicken       3.908072         0.328673\n",
      "8        staff       4.008584         0.666166\n",
      "9   atmosphere       4.210084         0.528197\n",
      "10        meal       3.700389         0.452940\n",
      "11       salad       3.972067         0.384627\n",
      "12        menu       3.869658         0.323725\n",
      "13      dinner       3.978056         0.396223\n",
      "Spearman Correlation Score:  0.4241758241758242\n",
      "Running on restaurant  ujHiaprwCQ5ewziu0Vi9rw ...\n",
      "Number of Reviews left after subset length:  1698\n",
      "Extracting entities from each review...\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n",
      "Rankings result: \n",
      "       entity  average_stars  predicted_score\n",
      "0        crab       3.396911         0.161159\n",
      "1      dinner       3.526952         0.162276\n",
      "2      buffet       3.399582         0.249804\n",
      "3       price       3.330591         0.202737\n",
      "4       place       3.265097         0.197714\n",
      "5   breakfast       3.678261         0.238274\n",
      "6        food       3.294837         0.227191\n",
      "7     service       3.393973         0.338629\n",
      "8     seafood       3.586146         0.270840\n",
      "9         bit       3.510909         0.219613\n",
      "10      staff       3.147766         0.366500\n",
      "11      sushi       3.466799         0.147704\n",
      "12      lunch       3.677989         0.108000\n",
      "13    dessert       3.586803         0.347186\n",
      "14       beef       3.603960         0.216680\n",
      "15       meal       3.264059         0.308932\n",
      "16     salmon       3.537530         0.305970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|                                    | 4/50 [10:48<2:10:48, 170.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation Score:  -0.2034313725490196\n",
      "Running on restaurant  OVTZNSkSfbl3gVB9XQIJfw ...\n",
      "Number of Reviews left after subset length:  561\n",
      "Extracting entities from each review...\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|                                    | 5/50 [12:25<1:51:23, 148.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rankings result: \n",
      "      entity  average_stars  predicted_score\n",
      "0       crab       3.254795         0.238798\n",
      "1     buffet       3.224237         0.226966\n",
      "2      place       3.154519         0.206971\n",
      "3       food       3.134766         0.248967\n",
      "4    service       3.179104         0.499511\n",
      "5      price       3.275229         0.289321\n",
      "6     dinner       3.231343         0.178405\n",
      "7  breakfast       3.357759         0.176983\n",
      "8       beer       3.394886         0.312853\n",
      "Spearman Correlation Score:  -0.016666666666666666\n",
      "Running on restaurant  HhVmDybpU7L50Kb5A0jXTg ...\n",
      "Number of Reviews left after subset length:  1600\n",
      "Extracting entities from each review...\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|                                   | 6/50 [16:59<2:16:35, 186.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rankings result: \n",
      "        entity  average_stars  predicted_score\n",
      "0   restaurant       3.180046         0.271916\n",
      "1       burger       3.547432         0.293195\n",
      "2        place       3.325500         0.276737\n",
      "3      service       3.419381         0.395419\n",
      "4         food       3.323452         0.357656\n",
      "5        table       2.919732         0.230233\n",
      "6         menu       3.347826         0.290400\n",
      "7       cheese       3.564815         0.237666\n",
      "8        staff       3.508065         0.430834\n",
      "9          bit       3.387805         0.225122\n",
      "10        beer       3.432292         0.198074\n",
      "11        meal       3.326829         0.390975\n",
      "12   breakfast       3.484962         0.197310\n",
      "13      dinner       3.458537         0.216480\n",
      "14         mac       3.651111         0.320250\n",
      "15    sandwich       3.502232         0.191443\n",
      "16        pork       3.531532         0.246149\n",
      "17       price       3.142105         0.135706\n",
      "18     chicken       3.301818         0.182566\n",
      "19     burgers       3.512552         0.406938\n",
      "20       trash       3.700855         0.193652\n",
      "21       fries       3.464529         0.333772\n",
      "Spearman Correlation Score:  0.14963297571993225\n",
      "Running on restaurant  XXW_OFaYQkkGOGniujZFHg ...\n",
      "Number of Reviews left after subset length:  1709\n",
      "Extracting entities from each review...\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|                                  | 7/50 [21:50<2:35:58, 217.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rankings result: \n",
      "        entity  average_stars  predicted_score\n",
      "0        place       4.010620         0.375886\n",
      "1      service       3.852230         0.496235\n",
      "2         food       3.917914         0.456679\n",
      "3   atmosphere       4.151436         0.486064\n",
      "4    breakfast       4.143617         0.315778\n",
      "5          bit       3.694704         0.212706\n",
      "6         meal       3.967667         0.310104\n",
      "7        decor       4.000000         0.341762\n",
      "8        price       3.952672         0.515907\n",
      "9         menu       4.066667         0.345984\n",
      "10     chicken       3.869048         0.366890\n",
      "11       staff       4.138554         0.598771\n",
      "12  restaurant       3.901387         0.258688\n",
      "13       diner       3.900000         0.283554\n",
      "14    cocktail       4.091988         0.326281\n",
      "15      prices       4.032143         0.419524\n",
      "16      dinner       3.958904         0.302950\n",
      "17      burger       3.732143         0.377404\n",
      "18    fireside       4.210375         0.346168\n",
      "19      lounge       4.179819         0.410079\n",
      "20       table       3.768775         0.284524\n",
      "Spearman Correlation Score:  0.3051948051948052\n",
      "Running on restaurant  Wxxvi3LZbHNIDwJ-ZimtnA ...\n",
      "Number of Reviews left after subset length:  1195\n",
      "Extracting entities from each review...\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|                                 | 8/50 [25:15<2:29:44, 213.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rankings result: \n",
      "    entity  average_stars  predicted_score\n",
      "0    staff       3.993600         0.543224\n",
      "1    price       3.900542         0.347244\n",
      "2     food       4.048000         0.475320\n",
      "3  service       3.663208         0.338783\n",
      "4    place       3.962097         0.422241\n",
      "5    rooms       4.058197         0.455521\n",
      "6  gondola       4.423077         0.349700\n",
      "7    decor       4.232493         0.497449\n",
      "8   casino       4.071928         0.389100\n",
      "Spearman Correlation Score:  0.35\n",
      "Running on restaurant  thLX_k20SPJ0KyusGTBIHw ...\n",
      "Number of Reviews left after subset length:  615\n",
      "Extracting entities from each review...\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|                                | 9/50 [27:00<2:03:48, 181.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rankings result: \n",
      "       entity  average_stars  predicted_score\n",
      "0       place       3.977427         0.462271\n",
      "1       staff       4.101010         0.578469\n",
      "2     service       3.701422         0.433312\n",
      "3        food       3.838710         0.530573\n",
      "4     chicken       4.094595         0.174382\n",
      "5  restaurant       3.623457         0.497161\n",
      "6  margaritas       4.208000         0.566877\n",
      "7        menu       4.036765         0.531842\n",
      "8       steak       4.155963         0.252506\n",
      "9       salsa       3.891720         0.398121\n",
      "Spearman Correlation Score:  0.1515151515151515\n",
      "Running on restaurant  uuGL8diLlHfeUeFuod3F-w ...\n",
      "Number of Reviews left after subset length:  923\n",
      "Extracting entities from each review...\n",
      "Filtering entities to have enough reviews...\n",
      "Calculating Yelp Star Rankings... \n",
      "Calculating Prediction Rankings...\n",
      "Performing sentiment analysis for each review... \n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "correlation_scores = []\n",
    "\n",
    "# Initialize predictor\n",
    "predictor = Predictor()\n",
    "\n",
    "for bus_id in tqdm(business_ids_similar_stars):\n",
    "    print(\"Running on restaurant \", bus_id, \"...\")\n",
    "    subset = bus[bus.business_id == bus_id]\n",
    "    \n",
    "    # only get reviews with enough amount of text\n",
    "    reviews_subset = [review for review in subset.text if len(review) < 400]\n",
    "\n",
    "    print(\"Number of Reviews left after subset length: \", len(reviews_subset))\n",
    "    \n",
    "    # get set of entities for this particular restaurant,\n",
    "    # and count how many reviews each entity have\n",
    "    entities_with_count = defaultdict(int) \n",
    "    review_entities = [] # extract entities for each review\n",
    "    print(\"Extracting entities from each review...\")\n",
    "    for review in reviews_subset:\n",
    "        entities = get_entities(nlp, review)\n",
    "\n",
    "        # add this review as a count to an entity\n",
    "        for ent in entities:\n",
    "            entities_with_count[ent.lower()] += 1\n",
    "\n",
    "        review_entities.append(entities)\n",
    "        \n",
    "    # only grab entities that have enough reviews\n",
    "    print(\"Filtering entities to have enough reviews...\")\n",
    "    entities_with_enough_reviews = []\n",
    "    threshold = 30\n",
    "    for key, value in entities_with_count.items():\n",
    "        if value >= threshold:\n",
    "            entities_with_enough_reviews.append(key)\n",
    "            \n",
    "    # TRUE RANKINGS CALCULATION\n",
    "    # for each entity, average ratings\n",
    "    true_rankings = defaultdict(list)\n",
    "\n",
    "    print(\"Calculating Yelp Star Rankings... \")\n",
    "    for entity in entities_with_enough_reviews:\n",
    "        true_rankings['entity'] += [entity]\n",
    "        entity_reviews = subset[subset.text.str.contains(entity, case=False)]\n",
    "        true_rankings['average_stars'] += [np.mean(entity_reviews.stars)]\n",
    "\n",
    "    true_rankings = pd.DataFrame(true_rankings)\n",
    "    \n",
    "    # PREDICTION RANKING CALCULATION\n",
    "    print(\"Calculating Prediction Rankings...\")\n",
    "    # Filter entities of each review to be from the entities_with_enough_review set\n",
    "    entity_filter = set(entities_with_enough_reviews)\n",
    "\n",
    "    filtered_entities = []\n",
    "\n",
    "    for entities in review_entities:\n",
    "        filtered = []\n",
    "        for ent in entities:\n",
    "            ent = ent.lower()\n",
    "            if ent in entity_filter:\n",
    "                filtered.append(ent)\n",
    "        filtered_entities.append(filtered)\n",
    "    \n",
    "    # perform sentiment analysis for each review with filtered entities above\n",
    "    predicted_scores = defaultdict(list)\n",
    "\n",
    "    print(\"Performing sentiment analysis for each review... \")\n",
    "    for i, review in enumerate(reviews_subset):\n",
    "        scores = predictor.customPredict(review, 7)\n",
    "        # save results \n",
    "        for entity, score in scores[0]:\n",
    "            predicted_scores[entity] += [score]\n",
    "\n",
    "    # create rankings from scores\n",
    "    predicted_rankings = defaultdict(list)\n",
    "    for entity, scores in predicted_scores.items():\n",
    "        predicted_rankings['entity'] += [entity]\n",
    "        predicted_rankings['predicted_score'] += [np.mean(scores)]\n",
    "    predicted_rankings = pd.DataFrame(predicted_rankings)\n",
    "    #### may not be necessary to do these castings\n",
    "    predicted_rankings['entity'] = predicted_rankings['entity'].astype(str)\n",
    "    true_rankings['entity'] = true_rankings['entity'].astype(str)\n",
    "    ####\n",
    "    \n",
    "    full_rankings = true_rankings.merge(predicted_rankings, how='left').fillna(0)\n",
    "\n",
    "    # spearman correlation metric\n",
    "    print(\"Rankings result: \")\n",
    "    print(full_rankings)\n",
    "    \n",
    "    corr, pvalue = spearmanr(full_rankings.average_stars, full_rankings.predicted_score)\n",
    "    print(\"Spearman Correlation Score: \", corr)\n",
    "    correlation_scores.append(corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(correlation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_bus = []\n",
    "for bus_id in tqdm(business_ids_similar_stars):\n",
    "    print(\"Running on restaurant \", bus_id, \"...\")\n",
    "    subset = bus[bus.business_id == bus_id]\n",
    "    \n",
    "    # only get reviews with enough amount of text\n",
    "    reviews_subset = [review for review in subset.text if len(review) < 400]\n",
    "\n",
    "    print(\"Number of Reviews left after subset length: \", len(reviews_subset))\n",
    "    \n",
    "    # get set of entities for this particular restaurant,\n",
    "    # and count how many reviews each entity have\n",
    "    entities_with_count = defaultdict(int) \n",
    "    review_entities = [] # extract entities for each review\n",
    "    print(\"Extracting entities from each review...\")\n",
    "    for review in tqdm(reviews_subset):\n",
    "        entities = get_entities(nlp, review)\n",
    "\n",
    "        # add this review as a count to an entity\n",
    "        for ent in entities:\n",
    "            entities_with_count[ent.lower()] += 1\n",
    "\n",
    "        review_entities.append(entities)\n",
    "        \n",
    "    # only grab entities that have enough reviews\n",
    "    print(\"Filtering entities to have enough reviews...\")\n",
    "    entities_with_enough_reviews = []\n",
    "    threshold = 30\n",
    "    for key, value in entities_with_count.items():\n",
    "        if value >= threshold:\n",
    "            entities_with_enough_reviews.append(key)\n",
    "            \n",
    "    # TRUE RANKINGS CALCULATION\n",
    "    # for each entity, average ratings\n",
    "    true_rankings = defaultdict(list)\n",
    "\n",
    "    print(\"Calculating Yelp Star Rankings... \")\n",
    "    for entity in entities_with_enough_reviews:\n",
    "        true_rankings['entity'] += [entity]\n",
    "        entity_reviews = subset[subset.text.str.contains(entity, case=False)]\n",
    "        true_rankings['average_stars'] += [np.mean(entity_reviews.stars)]\n",
    "\n",
    "    true_rankings = pd.DataFrame(true_rankings)\n",
    "    std_bus.append(np.std(true_rankings.average_stars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(std_bus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(std_bus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean =std_bus > np.mean(std_bus) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import compress\n",
    "np.mean(list(compress(correlation_scores, boolean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stars in full_rankings.average_stars:\n",
    "    print(np.std(stars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_subset[1023]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_sentiment(review, entities, parser = parser, sentiment_package='vader', rule=rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final Correlation Score: \", np.mean(correlation_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
